{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from icecream import ic\n",
    "from scipy import stats\n",
    "import toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_base_dir = '/home/skowshik/ADRD_repo/data/'\n",
    "save_base_dir = '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/'\n",
    "\n",
    "def get_zip_files(df, fea):\n",
    "    zip_files = []\n",
    "    for fn in list(df[fea]):\n",
    "        if isinstance(fn, str):\n",
    "            if fn.endswith('.zip'):\n",
    "                zip_files.append(fn)\n",
    "            else:\n",
    "                zip_files.append(np.NaN) \n",
    "        else:\n",
    "            zip_files.append(np.NaN)\n",
    "    return zip_files\n",
    "\n",
    "def correction(filepath, fea):\n",
    "    df = pd.read_csv(read_base_dir + filepath)\n",
    "    # print(df[~df['filename'].isna()])\n",
    "    df['mri_zip'] = get_zip_files(df, fea)\n",
    "    df.drop('filename', axis=1, inplace=True)\n",
    "    if 'path' in df:\n",
    "        df.drop('path', axis=1, inplace=True)\n",
    "    if 'filename_vit_emb' in df:\n",
    "        df.drop('filename_vit_emb', axis=1, inplace=True)\n",
    "    df['bat_OTRLARR'] = df['bat_OTRLARR'].replace({88: np.NaN, 95: np.NaN, 96: np.NaN, 97: np.NaN, 98: np.NaN, 888: np.NaN, 995: np.NaN, 996: np.NaN, 997: np.NaN, 998: np.NaN, -4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['bat_OTRLALI'] = df['bat_OTRLALI'].replace({88: np.NaN, 95: np.NaN, 96: np.NaN, 97: np.NaN, 98: np.NaN, 888: np.NaN, 995: np.NaN, 996: np.NaN, 997: np.NaN, 998: np.NaN, -4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['bat_OTRLBRR'] = df['bat_OTRLBRR'].replace({88: np.NaN, 95: np.NaN, 96: np.NaN, 97: np.NaN, 98: np.NaN, 888: np.NaN, 995: np.NaN, 996: np.NaN, 997: np.NaN, 998: np.NaN, -4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['bat_OTRLBLI'] = df['bat_OTRLBLI'].replace({88: np.NaN, 95: np.NaN, 96: np.NaN, 97: np.NaN, 98: np.NaN, 888: np.NaN, 995: np.NaN, 996: np.NaN, 997: np.NaN, 998: np.NaN, -4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "\n",
    "    df.to_csv(save_base_dir + filepath, index=False)\n",
    "    return df\n",
    "    \n",
    "\n",
    "df1 = correction('training_cohorts/new_nacc_revised_selection.csv', fea='filename')\n",
    "df2 = correction('train_vld_test_split_updated/nacc_neuropath.csv', fea='filename')\n",
    "df3 = correction('train_vld_test_split_updated/nacc_test_with_np_cli.csv', fea='mri_zip')\n",
    "df4 = correction('train_vld_test_split_updated/nacc_neuropath_test.csv', fea='mri_zip')\n",
    "df5 = correction('train_vld_test_split_updated/clinician_review_cases_test.csv', fea='mri_zip')\n",
    "df6 = correction('train_vld_test_split_updated/radiologist_review_cases_test.csv', fea='mri_zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_nacc = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/nacc.csv')\n",
    "# Train set\n",
    "nacc_all = pd.read_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/new_nacc_revised_selection.csv')\n",
    "\n",
    "aibl = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/AIBL.csv')\n",
    "nifd = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/NIFD.csv')\n",
    "ppmi = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/PPMI.csv')\n",
    "stanford = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/Stanford.csv')\n",
    "oasis_ov = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/OASIS.csv') # has overlapping cases\n",
    "oasis_wo_nacc = pd.read_excel('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/OASIS_without_NACC.xlsx')\n",
    "oasis = oasis_ov[oasis_ov['filename'].isin(list(oasis_wo_nacc['filename']))]\n",
    "\n",
    "# Test set\n",
    "adni1 = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/ADNI1.csv')\n",
    "adni2 = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/ADNI2.csv')\n",
    "adni3 = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/ADNI3.csv')\n",
    "adni_go = pd.read_csv('/home/skowshik/ADRD_repo/other_data/adni_aibl_nacc_nifd_oasis_ppmi/ADNIGO.csv')\n",
    "# fhs = pd.read_csv('/data_1/csv_files/FHS.csv')\n",
    "nacc_np = pd.read_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/nacc_neuropath.csv')\n",
    "nacc_np = nacc_all[nacc_all['ID'].isin(nacc_np['ID'])]\n",
    "\n",
    "cli = pd.read_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/clinician_review_cases_test.csv')\n",
    "cli = nacc_all[nacc_all['ID'].isin(cli['ID'])]\n",
    "\n",
    "nacc = nacc_all[(~nacc_all['ID'].isin(nacc_np['ID'])) & (~nacc_all['ID'].isin(cli['ID']))]\n",
    "# FHS\n",
    "# BMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adni1['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nacc['path'] = np.NaN\n",
    "adni1['path'] = '/data_1/ADNI1/'\n",
    "adni2['path'] = '/data_1/ADNI2/'\n",
    "adni3['path'] = '/data_1/ADNI3/'\n",
    "adni_go['path'] = '/data_1/ADNIGO/'\n",
    "aibl['path'] = '/data_1/AIBL/'\n",
    "nifd['path'] = '/data_1/NIFD/'\n",
    "ppmi['path'] = '/data_1/PPMI/'\n",
    "stanford['path'] = '/data_1/Stanford/npy/'\n",
    "oasis['path'] = '/data_1/OASIS_/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbd(row):\n",
    "    if row['PDD'] == 1 or row['DLB'] == 1:\n",
    "        return 1\n",
    "    elif row['PDD'] == 0 and row['DLB'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.NaN\n",
    "    \n",
    "def extract_id(row):\n",
    "    if ('ID' not in dict(row).keys() ) | pd.isna(row['ID']):\n",
    "        if 'adni' in row['path'].lower():\n",
    "            return '_'.join(row['filename'].split('_')[0:4])\n",
    "        elif 'aibl' in row['path'].lower():\n",
    "            return '_'.join(row['filename'].split('_')[0:2])\n",
    "        elif 'nifd' in row['path'].lower():\n",
    "            return '_'.join(row['filename'].split('_')[0:4])\n",
    "        elif 'oasis' in row['path'].lower():\n",
    "            return '_'.join(row['filename'].split('_')[0:2])\n",
    "        elif 'ppmi' in row['path'].lower():\n",
    "            return '_'.join(row['filename'].split('_')[0:2])\n",
    "        elif 'stanford' in row['path'].lower():\n",
    "            return 'STANFORD_' + row['filename'].split('.')[0]\n",
    "        else:\n",
    "            return np.NaN\n",
    "    else:\n",
    "        return row['ID']\n",
    "\n",
    "def convert_dataset(df):\n",
    "    if 'ID' not in df.columns:\n",
    "        df['ID'] = np.NaN\n",
    "    df['ID'] = df.apply(extract_id, axis=1)\n",
    "    if 'age' in df.columns:\n",
    "        df['his_NACCAGE'] = df['age'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('age', axis=1, inplace=True)\n",
    "    if 'gender' in df.columns:\n",
    "        df['his_SEX'] = df['gender'].replace({-4: np.NaN, '-4':np.NaN})\n",
    "        df.drop('gender', axis=1, inplace=True)\n",
    "    if 'education' in df.columns:\n",
    "        df['his_EDUC'] = df['education'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('education', axis=1, inplace=True)\n",
    "    if 'hispanic' in df.columns:\n",
    "        df['his_HISPANIC'] = df['hispanic'].replace({-4: np.NaN, '-4':np.NaN}).replace({1: 'yes', 2: 'no', 3: np.NaN, '1': 'yes', '2': 'no', '3': np.NaN, '1.0': 'yes', '2.0': 'no','3.0': np.NaN})\n",
    "        df.drop('hispanic', axis=1, inplace=True)\n",
    "    if 'race' in df.columns:\n",
    "        df['his_NACCNIHR'] = df['race'].replace({-4: np.NaN, '-4':np.NaN}).replace({'mix': 'mul', 'ans': 'asi'})\n",
    "        df.drop('race', axis=1, inplace=True)\n",
    "    if 'mmse' in df.columns:\n",
    "        df['bat_NACCMMSE'] = df['mmse'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('mmse', axis=1, inplace=True)\n",
    "    if 'moca' in df.columns:\n",
    "        df['bat_NACCMOCA'] = df['moca'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('moca', axis=1, inplace=True)\n",
    "    if 'apoe' in df.columns:\n",
    "        df['apoe_NACCNE4S'] = df['apoe'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('apoe', axis=1, inplace=True)\n",
    "    if 'DLB' in df.columns and 'PDD' in df.columns:\n",
    "        df['LBD'] = df.apply(lbd, axis=1)\n",
    "    if 'trailA' in df.columns:\n",
    "        df['bat_TRAILA'] = df['trailA'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('trailA', axis=1, inplace=True)\n",
    "    if 'trailB' in df.columns:\n",
    "        df['bat_TRAILB'] = df['trailB'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('trailB', axis=1, inplace=True)\n",
    "    if 'boston' in df.columns:\n",
    "        df['bat_BOSTON'] = df['boston'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('boston', axis=1, inplace=True)\n",
    "    if 'digitB' in df.columns:\n",
    "        df['bat_DIGIB'] = df['digitB'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('digitB', axis=1, inplace=True)\n",
    "    if 'digitBL' in df.columns:\n",
    "        df['bat_DIGIBLEN'] = df['digitBL'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('digitBL', axis=1, inplace=True)\n",
    "    if 'digitF' in df.columns:\n",
    "        df['bat_DIGIF'] = df['digitF'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('digitF', axis=1, inplace=True)\n",
    "    if 'digitFL' in df.columns:\n",
    "        df['bat_DIGIFLEN'] = df['digitFL'].replace({-4: np.NaN, '-4':np.NaN, 9: np.NaN}).astype(float)\n",
    "        df.drop('digitFL', axis=1, inplace=True)\n",
    "    if 'animal' in df.columns:\n",
    "        df['bat_ANIMALS'] = df['animal'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('animal', axis=1, inplace=True)\n",
    "    if 'his_Alcohol' in df.columns:\n",
    "        df['his_ALCOHOL'] = df['his_Alcohol'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('his_Alcohol', axis=1, inplace=True)\n",
    "    if 'gds' in df.columns:\n",
    "        df['gds_NACCGDS'] = df['gds'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('gds', axis=1, inplace=True)\n",
    "    if 'lm_imm' in df.columns:\n",
    "        df['bat_LOGIMEM'] = df['lm_imm'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('lm_imm', axis=1, inplace=True)\n",
    "    if 'lm_del' in df.columns:\n",
    "        df['bat_MEMUNITS'] = df['lm_del'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('lm_del', axis=1, inplace=True)\n",
    "    if 'his_TOBAC100' in df.columns:\n",
    "        df['his_TOBAC100'] = df['his_TOBAC100'].replace({-4: np.NaN, '-4':np.NaN}).replace({2: np.NaN, 3: np.NaN}).astype(float)\n",
    "    if 'cdr' in df.columns:\n",
    "        df['cdr_CDRGLOB'] = df['cdr'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('cdr', axis=1, inplace=True)\n",
    "    if 'cdrSum' in df.columns:\n",
    "        df['cdr_CDRSUM'] = df['cdrSum'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "        df.drop('cdrSum', axis=1, inplace=True)\n",
    "\n",
    "    if 'faq_BILLS' in df.columns:\n",
    "        df['faq_BILLS'] = df['faq_BILLS'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_TAXES' in df.columns:\n",
    "        df['faq_TAXES'] = df['faq_TAXES'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_SHOPPING' in df.columns:\n",
    "        df['faq_SHOPPING'] = df['faq_SHOPPING'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_GAMES' in df.columns:\n",
    "        df['faq_GAMES'] = df['faq_GAMES'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_STOVE' in df.columns:\n",
    "        df['faq_STOVE'] = df['faq_STOVE'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_MEALPREP' in df.columns:\n",
    "        df['faq_MEALPREP'] = df['faq_MEALPREP'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_EVENTS' in df.columns:\n",
    "        df['faq_EVENTS'] = df['faq_EVENTS'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_PAYATTN' in df.columns:\n",
    "        df['faq_PAYATTN'] = df['faq_PAYATTN'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_REMDATES' in df.columns:\n",
    "        df['faq_REMDATES'] = df['faq_REMDATES'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    if 'faq_TRAVEL' in df.columns:\n",
    "        df['faq_TRAVEL'] = df['faq_TRAVEL'].replace({-4: np.NaN, '-4':np.NaN}).replace({-1: np.NaN}).astype(float)\n",
    "    # df['ODE'] = df['OTHER']\n",
    "    df.drop('OTHER', axis=1, inplace=True)\n",
    "    df.drop('PD', axis=1, inplace=True)\n",
    "    df.drop('filename', axis=1, inplace=True)\n",
    "    df.drop('path', axis=1, inplace=True)\n",
    "    # df.drop('FTD', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['NC', 'MCI', 'DE', 'AD', 'LBD', 'DLB', 'PDD', 'VD', 'PRD', 'FTD', 'NPH', 'SEF', 'PSY', 'TBI', 'ODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_convert_dataset(df, filepath):\n",
    "    df = convert_dataset(df)\n",
    "    df_lbl = df[[label for label in labels if label in df.columns]]\n",
    "    df_lbl = df_lbl.dropna(how='all')\n",
    "    print('Out of {} samples, {} are dropped due to complete label missing for {}.'.format(len(df), len(df) - len(df_lbl), filepath.split('/')[-1]))\n",
    "    df = df[df.index.isin(df_lbl.index)]\n",
    "    avail_columns = [col for col in df.columns if col in nacc.columns]\n",
    "    intersect_columns = [label for label in labels if label in avail_columns]\n",
    "    other_columns = list(set(avail_columns) - set(intersect_columns))\n",
    "    df = df[intersect_columns + other_columns].reset_index(drop=True)\n",
    "    # print(df)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(len(df[(df['NC'] == 0) & (df['MCI'] == 0) & (df['DE'] == 0)]))\n",
    "    print(len(df[df['NC'] == 1]) + len(df[df['MCI'] == 1]) + len(df[df['DE'] == 1]) == len(df))\n",
    "    print(set(df[df['NC'] == 1]['ID']).intersection(set(df[df['MCI'] == 1]['ID'])))\n",
    "    print(set(df[df['NC'] == 1]['ID']).intersection(set(df[df['DE'] == 1]['ID'])))\n",
    "    print(set(df[df['DE'] == 1]['ID']).intersection(set(df[df['MCI'] == 1]['ID'])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 819 samples, 0 are dropped due to complete label missing for adni1_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 722 samples, 0 are dropped due to complete label missing for adni2_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 145 samples, 0 are dropped due to complete label missing for adni3_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 135 samples, 0 are dropped due to complete label missing for adni_go_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 664 samples, 3 are dropped due to complete label missing for aibl_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 307 samples, 54 are dropped due to complete label missing for nifd_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 625 samples, 427 are dropped due to complete label missing for ppmi_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 182 samples, 0 are dropped due to complete label missing for stanford_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "Out of 491 samples, 0 are dropped due to complete label missing for oasis_revised.csv.\n",
      "0\n",
      "True\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "adni1 = save_convert_dataset(adni1, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni1_revised.csv')\n",
    "adni2 = save_convert_dataset(adni2, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni2_revised.csv')\n",
    "adni3 = save_convert_dataset(adni3, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni3_revised.csv')\n",
    "adni_go = save_convert_dataset(adni_go, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni_go_revised.csv')\n",
    "aibl = save_convert_dataset(aibl, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/aibl_revised.csv')\n",
    "nifd = save_convert_dataset(nifd, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/nifd_revised.csv')\n",
    "ppmi = save_convert_dataset(ppmi, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/ppmi_revised.csv')\n",
    "stanford = save_convert_dataset(stanford, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/stanford_revised.csv')\n",
    "oasis = save_convert_dataset(oasis, '/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/oasis_revised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4RTNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtni = pd.read_csv('/home/skowshik/ADRD_repo/other_data/4RTNI/4RTNI_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUBID', 'DX', 'DDURATION', 'AUTOPSYDATE', 'AUTOPSYPX', 'SEX', 'AGE_AT_TP0', 'EDUCATION', 'RACE', 'LATINO', 'SCANID_0', 'BIOSPECIMENS_0_SERUM', 'BIOSPECIMENS_0_PLASMA', 'BIOSPECIMENS_0_URINE', 'BIOSPECIMENS_0_CSF', 'PSPRS_0_DATE', 'PSPRS_0_IMPUTED', 'PSPRS_0_TOTAL', 'PSPRS_0_SUBSCORE_HISTORY', 'PSPRS_0_SUBSCORE_MENTATION', 'PSPRS_0_SUBSCORE_BULBAR', 'PSPRS_0_SUBSCORE_OCULARMOTOR', 'PSPRS_0_SUBSCORE_LIMBMOTOR', 'PSPRS_0_SUBSCORE_GAITMIDLINE', 'PSPRS_0_MEDS', 'SEADL_0_DATE', 'SEADL_0', 'CGI_S_0_DATE', 'CGI_S_0', 'UPDRS_0_DATE', 'UPDRS_0_IMPUTED', 'UPDRS_0_TOTAL', 'UPDRS_0_PDNORMAL', 'MOCA_0_DATE', 'MOCA_0_MOCATOTWITHEDUC', 'MOCA_0_BEFAFTNP', 'MOCA_0_LNGTH', 'MMSE_0_DATE', 'MMSE_0_MMSETOT', 'CVLT_0_DATE', 'CVLT_0_TRCOTOT', 'CVLT_0_CORR30', 'CVLT_0_CORR10', 'CVLT_0_CUEDCOR', 'CVLT_0_RECOG', 'CVLT_0_CORRLONG', 'BENSON_0_DATE', 'BENSON_0_MODREY', 'BENSON_0_REY10M', 'BENSON_0_REYRECG', 'DSYM_0_DATE', 'DSYM_0', 'MTRAILS_0_DATE', 'MTRAILS_0_MTTIME', 'MTRAILS_0_MTCORR', 'DSPAN_0_DATE', 'DSPAN_0_DIGITFW', 'DSPAN_0_DIGITBW', 'UDSTRAILS_0_DATE', 'UDSTRAILS_0_TRAILA', 'UDSTRAILS_0_TRAILALI', 'UDSTRAILS_0_TRAILB', 'UDSTRAILS_0_TRAILBLI', 'VERBFLU_DWORDS_0_DATE', 'VERBFLU_DWORDS_0_DCORR', 'VERBFLU_AN_0_DATE', 'VERBFLU_AN_0_ANCORR', 'BNT_0_DATE', 'BNT_0_BNTTOT', 'BNT_0_BNTCORR', 'STROOP_0_DATE', 'STROOP_0_STRPCNCOR', 'STROOP_0_STRPCOR', 'VOSP_0_DATE', 'VOSP_0_NUMBLOC', 'WRAT4_0_DATE', 'WRAT4_0_WRATTOT', 'GDS_0_DATE', 'GDS_0_GDSTOT', 'GDS_0_GDS15TO', 'SNQ22_0_DATE', 'SNQ22_0_QTOTC', 'NPI_Q_0_DATE', 'NPI_Q_0_DELUSN', 'NPI_Q_0_DELSEV', 'NPI_Q_0_DELDIS', 'NPI_Q_0_HLCNTNS', 'NPI_Q_0_HALSEV', 'NPI_Q_0_HALDIS', 'NPI_Q_0_AGITATE', 'NPI_Q_0_AGSEV', 'NPI_Q_0_AGDIS', 'NPI_Q_0_DPRSSN', 'NPI_Q_0_DEPSEV', 'NPI_Q_0_DEPDIS', 'NPI_Q_0_ANXIETY', 'NPI_Q_0_ANXSEV', 'NPI_Q_0_ANXDIS', 'NPI_Q_0_EUPHORIA', 'NPI_Q_0_EUPSEV', 'NPI_Q_0_EUPDIS', 'NPI_Q_0_APATHY', 'NPI_Q_0_APTHSEV', 'NPI_Q_0_APTHDIS', 'NPI_Q_0_DISINHIBITION', 'NPI_Q_0_DISSEV', 'NPI_Q_0_DISDIS', 'NPI_Q_0_IRRITBLE', 'NPI_Q_0_IRRSEV', 'NPI_Q_0_IRRDIS', 'NPI_Q_0_MOTOR', 'NPI_Q_0_MOTSEV', 'NPI_Q_0_MOTDIS', 'NPI_Q_0_SLEEP', 'NPI_Q_0_SLESEV', 'NPI_Q_0_SLEDIS', 'NPI_Q_0_EAT', 'NPI_Q_0_EATSEV', 'NPI_Q_0_EATDIS', 'CDR_0_DATE', 'CDR_0_CDRTOT', 'CDR_0_BOXSCORE', 'CDR_0_MEMORY', 'CDR_0_BEHAV', 'CDR_0_MOTOR', 'FAQ_0_DATE', 'FAQ_0_FAQTOT', 'IRI_0_DATE', 'IRI_0_IRIEC', 'IRI_0_IRIPT', 'RSMS_0_DATE', 'RSMS_0_RSMSTOTI', 'RSMS_0_RSMSSUB1I', 'RSMS_0_RSMSSUB2I', 'BIS_0_DATE', 'BIS_0_BIS_TOT', 'SCANID_6MO', 'BIOSPECIMENS_6MO_PLASMA', 'PSPRS_6MO_DATE', 'PSPRS_6MO_IMPUTED', 'PSPRS_6MO_TOTAL', 'PSPRS_6MO_SUBSCORE_HISTORY', 'PSPRS_6MO_SUBSCORE_MENTATION', 'PSPRS_6MO_SUBSCORE_BULBAR', 'PSPRS_6MO_SUBSCORE_OCULARMOTOR', 'PSPRS_6MO_SUBSCORE_LIMBMOTOR', 'PSPRS_6MO_SUBSCORE_GAITMIDLINE', 'PSPRS_6MO_MEDS', 'SEADL_6MO_DATE', 'SEADL_6MO', 'CGI_S_6MO_DATE', 'CGI_S_6MO', 'CGI_C_6MO_DATE', 'CGI_C_6MO', 'UPDRS_6MO_DATE', 'UPDRS_6MO_IMPUTED', 'UPDRS_6MO_TOTAL', 'UPDRS_6MO_PDNORMAL', 'MOCA_6MO_DATE', 'MOCA_6MO_MOCATOTWITHEDUC', 'MOCA_6MO_BEFAFTNP', 'MOCA_6MO_LNGTH', 'MMSE_6MO_DATE', 'MMSE_6MO_MMSETOT', 'CVLT_6MO_Date', 'CVLT_6MO_TRCOTOT', 'CVLT_6MO_CORR30', 'CVLT_6MO_CORR10', 'CVLT_6MO_CUEDCOR', 'CVLT_6MO_RECOG', 'CVLT_6MO_CORRLONG', 'BENSON_6MO_DATE', 'BENSON_6MO_MODREY', 'BENSON_6MO_REY10M', 'BENSON_6MO_REYRECG', 'DSYM_6MO_DATE', 'DSYM_6MO', 'MTRAILS_6MO_DATE', 'MTRAILS_6MO_MTTIME', 'MTRAILS_6MO_MTCORR', 'DSPAN_6MO_DATE', 'DSPAN_6MO_DIGITFW', 'DSPAN_6MO_DIGITBW', 'UDSTRAILS_6MO_DATE', 'UDSTRAILS_6MO_TRAILA', 'UDSTRAILS_6MO_TRAILALI', 'UDSTRAILS_6MO_TRAILB', 'UDSTRAILS_6MO_TRAILBLI', 'VERBFLU_DWORDS_6MO_DATE', 'VERBFLU_DWORDS_6MO_DCORR', 'VERBFLU_AN_6MO_DATE', 'VERBFLU_AN_6MO_ANCORR', 'BNT_6MO_DATE', 'BNT_6MO_BNTTOT', 'BNT_6MO_BNTCORR', 'STROOP_6MO_DATE', 'STROOP_6MO_STRPCNCOR', 'STROOP_6MO_STRPCOR', 'VOSP_6MO_DATE', 'VOSP_6MO_NUMBLOC', 'WRAT4_6MO_DATE', 'WRAT4_6MO_WRATTOT', 'GDS_6MO_DATE', 'GDS_6MO_GDSTOT', 'GDS_6MO_GDS15TO', 'SNQ22_6MO_DATE', 'SNQ22_6MO_QTOTC', 'NPI_Q_6MO_DATE', 'NPI_Q_6MO_DELUSN', 'NPI_Q_6MO_DELSEV', 'NPI_Q_6MO_DELDIS', 'NPI_Q_6MO_HLCNTNS', 'NPI_Q_6MO_HALSEV', 'NPI_Q_6MO_HALDIS', 'NPI_Q_6MO_AGITATE', 'NPI_Q_6MO_AGSEV', 'NPI_Q_6MO_AGDIS', 'NPI_Q_6MO_DPRSSN', 'NPI_Q_6MO_DEPSEV', 'NPI_Q_6MO_DEPDIS', 'NPI_Q_6MO_ANXIETY', 'NPI_Q_6MO_ANXSEV', 'NPI_Q_6MO_ANXDIS', 'NPI_Q_6MO_EUPHORIA', 'NPI_Q_6MO_EUPSEV', 'NPI_Q_6MO_EUPDIS', 'NPI_Q_6MO_APATHY', 'NPI_Q_6MO_APTHSEV', 'NPI_Q_6MO_APTHDIS', 'NPI_Q_6MO_DISINHIBITION', 'NPI_Q_6MO_DISSEV', 'NPI_Q_6MO_DISDIS', 'NPI_Q_6MO_IRRITBLE', 'NPI_Q_6MO_IRRSEV', 'NPI_Q_6MO_IRRDIS', 'NPI_Q_6MO_MOTOR', 'NPI_Q_6MO_MOTSEV', 'NPI_Q_6MO_MOTDIS', 'NPI_Q_6MO_SLEEP', 'NPI_Q_6MO_SLESEV', 'NPI_Q_6MO_SLEDIS', 'NPI_Q_6MO_EAT', 'NPI_Q_6MO_EATSEV', 'NPI_Q_6MO_EATDIS', 'CDR_6MO_DATE', 'CDR_6MO_CDRTOT', 'CDR_6MO_BOXSCORE', 'CDR_6MO_MEMORY', 'CDR_6MO_BEHAV', 'CDR_6MO_MOTOR', 'FAQ_6MO_DATE', 'FAQ_6MO_FAQTOT', 'IRI_6MO_DATE', 'IRI_6MO_IRIEC', 'IRI_6MO_IRIPT', 'RSMS_6MO_DATE', 'RSMS_6MO_RSMSTOTI', 'RSMS_6MO_RSMSSUB1I', 'RSMS_6MO_RSMSSUB2I', 'BIS_6MO_DATE', 'BIS_6MO_BIS_TOT', 'SCANID_12MO', 'BIOSPECIMENS_12MO_SERUM', 'BIOSPECIMENS_12MO_PLASMA', 'BIOSPECIMENS_12MO_URINE', 'BIOSPECIMENS_12MO_CSF', 'PSPRS_12MO_DATE', 'PSPRS_12MO_IMPUTED', 'PSPRS_12MO_TOTAL', 'PSPRS_12MO_SUBSCORE_HISTORY', 'PSPRS_12MO_SUBSCORE_MENTATION', 'PSPRS_12MO_SUBSCORE_BULBAR', 'PSPRS_12MO_SUBSCORE_OCULARMOTOR', 'PSPRS_12MO_SUBSCORE_LIMBMOTOR', 'PSPRS_12MO_SUBSCORE_GAITMIDLINE', 'PSPRS_12MO_MEDS', 'SEADL_12MO_DATE', 'SEADL_12MO', 'CGI_S_12MO_DATE', 'CGI_S_12MO', 'CGI_C_12MO_DATE', 'CGI_C_12MO', 'UPDRS_12MO_DATE', 'UPDRS_12MO_IMPUTED', 'UPDRS_12MO_TOTAL', 'UPDRS_12MO_PDNORMAL', 'MOCA_12MO_DATE', 'MOCA_12MO_MOCATOTWITHEDUC', 'MOCA_12MO_BEFAFTNP', 'MOCA_12MO_LNGTH', 'MMSE_12MO_DATE', 'MMSE_12MO_MMSETOT', 'CVLT_12MO_Date', 'CVLT_12MO_TRCOTOT', 'CVLT_12MO_CORR30', 'CVLT_12MO_CORR10', 'CVLT_12MO_CUEDCOR', 'CVLT_12MO_RECOG', 'CVLT_12MO_CORRLONG', 'BENSON_12MO_DATE', 'BENSON_12MO_MODREY', 'BENSON_12MO_REY10M', 'BENSON_12MO_REYRECG', 'DSYM_12MO_DATE', 'DSYM_12MO', 'MTRAILS_12MO_DATE', 'MTRAILS_12MO_MTTIME', 'MTRAILS_12MO_MTCORR', 'DSPAN_12MO_DATE', 'DSPAN_12MO_DIGITFW', 'DSPAN_12MO_DIGITBW', 'UDSTRAILS_12MO_DATE', 'UDSTRAILS_12MO_TRAILA', 'UDSTRAILS_12MO_TRAILALI', 'UDSTRAILS_12MO_TRAILB', 'UDSTRAILS_12MO_TRAILBLI', 'VERBFLU_DWORDS_12MO_DATE', 'VERBFLU_DWORDS_12MO_DCORR', 'VERBFLU_AN_12MO_DATE', 'VERBFLU_AN_12MO_ANCORR', 'BNT_12MO_DATE', 'BNT_12MO_BNTTOT', 'BNT_12MO_BNTCORR', 'STROOP_12MO_DATE', 'STROOP_12MO_STRPCNCOR', 'STROOP_12MO_STRPCOR', 'VOSP_12MO_DATE', 'VOSP_12MO_NUMBLOC', 'WRAT4_12MO_DATE', 'WRAT4_12MO_WRATTOT', 'GDS_12MO_DATE', 'GDS_12MO_GDSTOT', 'GDS_12MO_GDS15TO', 'SNQ22_12MO_DATE', 'SNQ22_12MO_QTOTC', 'NPI_Q_12MO_DATE', 'NPI_Q_12MO_DELUSN', 'NPI_Q_12MO_DELSEV', 'NPI_Q_12MO_DELDIS', 'NPI_Q_12MO_HLCNTNS', 'NPI_Q_12MO_HALSEV', 'NPI_Q_12MO_HALDIS', 'NPI_Q_12MO_AGITATE', 'NPI_Q_12MO_AGSEV', 'NPI_Q_12MO_AGDIS', 'NPI_Q_12MO_DPRSSN', 'NPI_Q_12MO_DEPSEV', 'NPI_Q_12MO_DEPDIS', 'NPI_Q_12MO_ANXIETY', 'NPI_Q_12MO_ANXSEV', 'NPI_Q_12MO_ANXDIS', 'NPI_Q_12MO_EUPHORIA', 'NPI_Q_12MO_EUPSEV', 'NPI_Q_12MO_EUPDIS', 'NPI_Q_12MO_APATHY', 'NPI_Q_12MO_APTHSEV', 'NPI_Q_12MO_APTHDIS', 'NPI_Q_12MO_DISINHIBITION', 'NPI_Q_12MO_DISSEV', 'NPI_Q_12MO_DISDIS', 'NPI_Q_12MO_IRRITBLE', 'NPI_Q_12MO_IRRSEV', 'NPI_Q_12MO_IRRDIS', 'NPI_Q_12MO_MOTOR', 'NPI_Q_12MO_MOTSEV', 'NPI_Q_12MO_MOTDIS', 'NPI_Q_12MO_SLEEP', 'NPI_Q_12MO_SLESEV', 'NPI_Q_12MO_SLEDIS', 'NPI_Q_12MO_EAT', 'NPI_Q_12MO_EATSEV', 'NPI_Q_12MO_EATDIS', 'CDR_12MO_DATE', 'CDR_12MO_CDRTOT', 'CDR_12MO_BOXSCORE', 'CDR_12MO_MEMORY', 'CDR_12MO_BEHAV', 'CDR_12MO_MOTOR', 'FAQ_12MO_DATE', 'FAQ_12MO_FAQTOT', 'IRI_12MO_DATE', 'IRI_12MO_IRIEC', 'IRI_12MO_IRIPT', 'RSMS_12MO_DATE', 'RSMS_12MO_RSMSTOTI', 'RSMS_12MO_RSMSSUB1I', 'RSMS_12MO_RSMSSUB2I', 'BIS_12MO_DATE', 'BIS_12MO_BIS_TOT', 'update_stamp']\n"
     ]
    }
   ],
   "source": [
    "print(list(rtni.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(rtni['SUBID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ftldvar(row):\n",
    "#     if row['DX'] == 'PSP' or row['DX'] == 'CBS':\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return np.NaN\n",
    "\n",
    "def rtni_labels(row):\n",
    "    if row['CDR_0_CDRTOT'] == 0:\n",
    "        row['NC'] = 1\n",
    "    else:\n",
    "        row['NC'] = 0\n",
    "    if (row['CDR_0_CDRTOT'] >= 0.5) & (row['FAQ_0_FAQTOT'] < 9):\n",
    "        row['MCI'] = 1\n",
    "    else:\n",
    "        row['MCI'] = 0\n",
    "    if (row['CDR_0_CDRTOT'] >= 1.0) & (row['FAQ_0_FAQTOT'] >= 9):\n",
    "        if row['DX'] == 'PSP' or row['DX'] == 'CBS':\n",
    "            row['DE'] = 1\n",
    "            row['FTD'] = 1\n",
    "        else:\n",
    "            row['DE'] = np.NaN\n",
    "            row['FTD'] = np.NaN\n",
    "    else:\n",
    "        row['DE'] = 0\n",
    "        row['FTD'] = 0\n",
    "    return row\n",
    "\n",
    "def extract_rtni_id(row):\n",
    "    return '4RTNI_' + row['SUBID']\n",
    "\n",
    "def data_convert_4rtni(df):\n",
    "    if 'ID' not in df.columns:\n",
    "        df['ID'] = np.NaN\n",
    "    df['ID'] = df.apply(extract_rtni_id, axis=1)\n",
    "    df['his_SEX'] = df['SEX'].replace({-4: np.NaN, '-4':np.NaN}).replace({'F': 'female', 'M': 'male'})\n",
    "    df['his_NACCAGE'] = df['AGE_AT_TP0'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['his_EDUC'] = df['EDUCATION'].replace({-4: np.NaN, '-4':np.NaN}).replace({99.0: np.NaN}).astype(float)\n",
    "    df['his_NACCNIHR'] = df['RACE'].replace({-4: np.NaN, '-4':np.NaN}).replace({1:'whi', 2:'blk', 3:'asi', 4:'haw', 5:'mul', 6:np.NaN})\n",
    "    df['his_HISPANIC'] = df['LATINO'].replace({-4: np.NaN, '-4':np.NaN}).replace({0: 'no', 1: 'yes', 2:np.NaN})\n",
    "    df['bat_NACCMOCA'] = df['MOCA_0_MOCATOTWITHEDUC'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['bat_NACCMMSE'] = df['MMSE_0_MMSETOT'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['bat_TRAILA'] = df['UDSTRAILS_0_TRAILA'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['bat_TRAILALI'] = df['UDSTRAILS_0_TRAILALI'].replace({-4: np.NaN, '-4':np.NaN, 71:np.NaN, 93:np.NaN}).astype(float)\n",
    "    df['bat_TRAILB'] = df['UDSTRAILS_0_TRAILB'].replace({-4: np.NaN, '-4':np.NaN, 995: np.NaN}).astype(float)\n",
    "    df['bat_TRAILBLI'] = df['UDSTRAILS_0_TRAILBLI'].replace({-4: np.NaN, '-4':np.NaN, 88:np.NaN, 300:np.NaN}).astype(float)\n",
    "    df['gds_NACCGDS'] = df['GDS_0_GDS15TO'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['updrs_PDNORMAL'] = df['UPDRS_0_PDNORMAL'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['cdr_CDRGLOB'] = df['CDR_0_CDRTOT'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['cdr_CDRSUM'] = df['CDR_0_BOXSCORE'].replace({-4: np.NaN, '-4':np.NaN}).astype(float)\n",
    "    df['npiq_DEL'] = np.where(df['NPI_Q_0_DELUSN'] == 2, 0, df['NPI_Q_0_DELSEV']).astype(float)\n",
    "    df['npiq_HALL'] = np.where(df['NPI_Q_0_HLCNTNS'] == 2, 0, df['NPI_Q_0_HALSEV']).astype(float)\n",
    "    df['npiq_AGIT'] = np.where(df['NPI_Q_0_AGITATE'] == 2, 0, df['NPI_Q_0_AGSEV']).astype(float)\n",
    "    df['npiq_DEPD'] = np.where(df['NPI_Q_0_DPRSSN'] == 2, 0, df['NPI_Q_0_DEPSEV']).astype(float)\n",
    "    df['npiq_ANX'] = np.where(df['NPI_Q_0_ANXIETY'] == 2, 0, df['NPI_Q_0_ANXSEV']).astype(float)\n",
    "    df['npiq_ELAT'] = np.where(df['NPI_Q_0_EUPHORIA'] == 2, 0, df['NPI_Q_0_EUPSEV']).astype(float)\n",
    "    df['npiq_APA'] = np.where(df['NPI_Q_0_APATHY'] == 2, 0, df['NPI_Q_0_APTHSEV']).astype(float)\n",
    "    df['npiq_DISN'] = np.where(df['NPI_Q_0_DISINHIBITION'] == 2, 0, df['NPI_Q_0_DISSEV']).astype(float)\n",
    "    df['npiq_IRR'] = np.where(df['NPI_Q_0_IRRITBLE'] == 2, 0, df['NPI_Q_0_IRRSEV']).astype(float)\n",
    "    df['npiq_MOT'] = np.where(df['NPI_Q_0_MOTOR'] == 2, 0, df['NPI_Q_0_MOTSEV']).astype(float)\n",
    "    df['npiq_NITE'] = np.where(df['NPI_Q_0_SLEEP'] == 2, 0, df['NPI_Q_0_SLESEV']).astype(float)\n",
    "    df['npiq_APP'] = np.where(df['NPI_Q_0_EAT'] == 2, 0, df['NPI_Q_0_EATSEV']).astype(float)\n",
    "    df = df.apply(rtni_labels, axis=1)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtni = data_convert_4rtni(rtni)[['ID', 'NC', 'MCI', 'DE', 'FTD', 'his_SEX', 'his_NACCAGE', 'his_EDUC', 'his_NACCNIHR', 'his_HISPANIC', 'bat_NACCMOCA', 'bat_NACCMMSE', 'bat_TRAILA', 'bat_TRAILALI', 'bat_TRAILB', 'bat_TRAILBLI', 'gds_NACCGDS', 'updrs_PDNORMAL', 'cdr_CDRGLOB', 'cdr_CDRSUM', 'npiq_DEL', 'npiq_HALL', 'npiq_AGIT', 'npiq_DEPD', 'npiq_ANX', 'npiq_ELAT', 'npiq_APA', 'npiq_DISN', 'npiq_IRR', 'npiq_MOT', 'npiq_NITE', 'npiq_APP', 'CDR_0_CDRTOT', 'FAQ_0_FAQTOT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtni = rtni[(rtni['NC'] == 1) | (rtni['MCI'] == 1) | (rtni['DE'] == 1)]\n",
    "rtni = rtni[~rtni['DE'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtni.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/rtni_revised.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(rtni[(rtni['NC'] == 0) & (rtni['MCI'] == 0) & (rtni['DE'] == 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([nacc, nifd, stanford, aibl, ppmi, oasis, rtni], axis=0)[nacc.columns]\n",
    "adni_df = pd.concat([adni1, adni2, adni3, adni_go], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ADNI further conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(row):\n",
    "    if ('ID' not in dict(row).keys() ) | pd.isna(row['ID']):\n",
    "        if 'adni' in row['path'].lower():\n",
    "            return '_'.join(row['filename'].split('_')[0:4])\n",
    "        else:\n",
    "            return np.NaN\n",
    "    else:\n",
    "        return row['ID']\n",
    "\n",
    "def data_convert_adni(df):\n",
    "    # if 'ID' not in df.columns:\n",
    "    #     df['ID'] = np.NaN\n",
    "    # df['ID'] = df.apply(extract_id, axis=1)\n",
    "    df['faq_BILLS'] = df['faq_BILLS'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_TAXES'] = df['faq_TAXES'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_SHOPPING'] = df['faq_SHOPPING'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_GAMES'] = df['faq_GAMES'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_STOVE'] = df['faq_STOVE'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_MEALPREP'] = df['faq_MEALPREP'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_EVENTS'] = df['faq_EVENTS'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_PAYATTN'] = df['faq_PAYATTN'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_REMDATES'] = df['faq_REMDATES'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['faq_TRAVEL'] = df['faq_TRAVEL'].replace({1: 0, 2: 1, 3: 1, 4: 2, 5: 3}).astype(float)\n",
    "    df['npiq_ANX'] = df['npiq_ANX'].replace({4: np.NaN}).astype(float)\n",
    "    df.drop('his_PACKSPER', axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_df = data_convert_adni(adni_df)\n",
    "adni1 = data_convert_adni(adni1)\n",
    "adni2 = data_convert_adni(adni2)\n",
    "adni3 = data_convert_adni(adni3)\n",
    "adni_go = data_convert_adni(adni_go)\n",
    "\n",
    "adni1.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni1_revised.csv', index=False)\n",
    "adni2.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni2_revised.csv', index=False)\n",
    "adni3.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni3_revised.csv', index=False)\n",
    "adni_go.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/testing_cohorts/adni_go_revised.csv', index=False)\n",
    "\n",
    "train_df.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/merged_data_nacc_nifd_stanford_aibl_ppmi_oasis_rtni_without_np_cli.csv', index=False)\n",
    "adni_df.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/adni_revised_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/training_cohorts/merged_data_nacc_nifd_stanford_aibl_ppmi_oasis_rtni.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adni neuropath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adni_np = pd.read_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/adni_neuropath.csv')\n",
    "# adni_df = pd.read_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/adni_revised_labels.csv')\n",
    "# adni_df['faq_BILLS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adni_prev_np = pd.read_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/adni_neuropath.csv')\n",
    "all_adni = pd.read_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/adni_revised_labels.csv')\n",
    "adni_np_orig = pd.read_csv('/home/skowshik/ADRD_repo/other_data/ADNI/Neuropathology_Results/NEUROPATH_02_06_23_25Jul2023.csv')\n",
    "# adni_np_all['mri_to_yod'] = adni_np_all['NPDAGE'] - adni_np_all['MRIYR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_798684/3400058808.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adni_np['RID'] = adni_np_rid\n"
     ]
    }
   ],
   "source": [
    "# prev_np_filenames = [fn.split('.')[0] + '.npy' for fn in list(all_prev_np[~all_prev_np['filename'].isna()]['filename'])]\n",
    "adni_np = all_adni[all_adni['ID'].isin(adni_prev_np['ID'])]\n",
    "adni_np_rid = [int(fn.split('_')[3]) for fn in list(adni_np['ID'])]\n",
    "adni_np['RID'] = adni_np_rid\n",
    "adni_np_orig_matched = adni_np_orig[adni_np_orig['RID'].isin(adni_np_rid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(adni_np, adni_np_orig_matched, on=[\"RID\"], how='left')\n",
    "merged_data.to_csv('/home/skowshik/ADRD_repo/pipeline_v1_main/adrd_tool/data/train_vld_test_split_updated/adni_neuropath.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2fee1eeda00f634ef393c368cf80d2602caace706932955f6e4df5f01719481"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
